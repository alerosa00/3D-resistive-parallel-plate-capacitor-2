{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4f59b9-e624-49ab-8cea-e83e98c483b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from pprint import pprint\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import torch.nn.init as init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36baf80c-5afa-40e4-9e29-714adde4c7a8",
   "metadata": {},
   "source": [
    "<h3>Geometry</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572a9484-e2c3-4c59-9aab-660f8b1c51e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_train_sigma = True   # == True if we have to train sigma approximation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935a66b7-e08e-4e56-85cc-3c2e2f7b3060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEVICE\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# PINN DEFAULT SETTING :\n",
    "f_batch = 1 #12\n",
    "PDE_batch_size  = 4096  * f_batch\n",
    "IC_batch_size   = 4096 * 4 * f_batch\n",
    "BC_batch_size   = 1024 * f_batch\n",
    "\n",
    "# GEOMETRY\n",
    "d = 80                          # [um] spazio tra le due armature del condensatore\n",
    "L = 100                         # [um] z_max - z_min\n",
    "h_arm = (L - d) / 2             # [um] spessore armatura\n",
    "lato = 1e3                      # [um] x_max-x_min e y_max-y_min\n",
    "\n",
    "# space\n",
    "x_min = -lato/2\n",
    "x_max = +lato/2\n",
    "y_min = -lato/2\n",
    "y_max = +lato/2\n",
    "z_min = -L/2\n",
    "z_max = +L/2\n",
    "factor_x, factor_y, factor_z = x_max-x_min, y_max-y_min, z_max-z_min\n",
    "\n",
    "# time\n",
    "t_min = 0\n",
    "t_max = 5\n",
    "factor_t = (t_max-t_min)\n",
    "c_time_err = 1e-2\n",
    "logt_min = np.log( t_min + c_time_err )\n",
    "logt_max = np.log( t_max + c_time_err )\n",
    "factor_logt = logt_max-logt_min\n",
    "\n",
    "\n",
    "V0 = 1\n",
    "E0 = V0 / ( z_max - z_min )\n",
    "\n",
    "\n",
    "# NORMALIZATION\n",
    "def Norm_time(time_coords):\n",
    "    if isinstance(time_coords, torch.Tensor):\n",
    "        return ( torch.log( time_coords + c_time_err ) ) / factor_logt\n",
    "    else:\n",
    "        return ( np.log( time_coords + c_time_err ) ) / factor_logt\n",
    "\n",
    "def Norm_space(space_coords):\n",
    "    if isinstance(space_coords, torch.Tensor):\n",
    "        return ( space_coords - torch.tensor([x_min, y_min, z_min], device=space_coords.device) ) \\\n",
    "                            / torch.tensor([factor_x, factor_y, factor_z], device=space_coords.device)\n",
    "    else:\n",
    "        return ( space_coords - np.array([x_min, y_min, z_min]) ) / np.array([factor_x, factor_y, factor_z])\n",
    "\n",
    "def Norm_x(x_coord):\n",
    "    return ( x_coord - x_min ) / factor_x\n",
    "\n",
    "def Norm_y(y_coord):\n",
    "    return ( y_coord - y_min ) / factor_y\n",
    "\n",
    "def Norm_z(z_coord):\n",
    "    return ( z_coord - z_min ) / factor_z\n",
    "\n",
    "def Norm_coords(coords):\n",
    "    time_coords = coords[:, 0]\n",
    "    space_coords = coords[:, 1:]\n",
    "    if isinstance(coords, torch.Tensor):\n",
    "        norm_t   = Norm_time(time_coords).unsqueeze(-1)\n",
    "        norm_xyz = Norm_space(space_coords)\n",
    "        return torch.cat([norm_t, norm_xyz], dim=1)\n",
    "    else:\n",
    "        norm_t   = Norm_time(time_coords)[:, np.newaxis]\n",
    "        norm_xyz = Norm_space(space_coords)\n",
    "        return np.concatenate([norm_t, norm_xyz], axis=1)\n",
    "\n",
    "# INVERSE OF NORMALIZATION\n",
    "def Inv_Norm_time(norm_time_coords):\n",
    "    if isinstance(norm_time_coords, torch.Tensor):\n",
    "        return ( torch.exp(norm_time_coords * factor_logt) - c_time_err )\n",
    "    else:\n",
    "        return ( np.exp(norm_time_coords * factor_logt) - c_time_err )\n",
    "\n",
    "def Inv_Norm_space(norm_space_coords):\n",
    "    if isinstance(norm_space_coords, torch.Tensor):\n",
    "        return norm_space_coords * torch.tensor([factor_x, factor_y, factor_z], device=norm_space_coords.device) \\\n",
    "                + torch.tensor([x_min, y_min, z_min], device=norm_space_coords.device)\n",
    "    else:\n",
    "        return norm_space_coords * np.array([factor_x, factor_y, factor_z]) \\\n",
    "                + np.array([x_min, y_min, z_min])\n",
    "\n",
    "def Inv_Norm_x(norm_x_coord):\n",
    "    return norm_x_coord * factor_x + x_min\n",
    "\n",
    "def Inv_Norm_y(norm_y_coord):\n",
    "    return norm_y_coord * factor_y + y_min\n",
    "\n",
    "def Inv_Norm_z(norm_z_coord):\n",
    "    return norm_z_coord * factor_z + z_min\n",
    "\n",
    "def Inv_Norm_coords(norm_coords):\n",
    "    norm_time_coords = norm_coords[:, 0]\n",
    "    norm_space_coords = norm_coords[:, 1:]\n",
    "    if isinstance(norm_coords, torch.Tensor):\n",
    "        time_coords = Inv_Norm_time(norm_time_coords).unsqueeze(-1)\n",
    "        space_coords = Inv_Norm_space(norm_space_coords)\n",
    "        return torch.cat([time_coords, space_coords], dim=1)\n",
    "    else:\n",
    "        time_coords = Inv_Norm_time(norm_time_coords)[:, np.newaxis]\n",
    "        space_coords = Inv_Norm_space(norm_space_coords)\n",
    "        return np.concatenate([time_coords, space_coords], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "normed = Norm_coords( torch.tensor([t_min, x_min, y_min, z_min], device=device).unsqueeze(0) )\n",
    "norm_t_min, norm_x_min, norm_y_min, norm_z_min = normed[0,0], normed[0,1], normed[0,2], normed[0,3]\n",
    "normed = Norm_coords( torch.tensor([t_max, x_max, y_max, z_max], device=device).unsqueeze(0) )\n",
    "norm_t_max, norm_x_max, norm_y_max, norm_z_max = normed[0,0], normed[0,1], normed[0,2], normed[0,3]\n",
    "print(\" \")\n",
    "print(\"real coordinates:\")\n",
    "print(f\"time : [{t_min},{t_max}], space : [{x_min},{x_max}]x[{y_min},{y_max}]x[{z_min},{z_max}]\")\n",
    "print(\"normalized coordinates:\")\n",
    "print(f\"time : [{norm_t_min},{norm_t_max}], space : [{norm_x_min},{norm_x_max}]x[{norm_y_min},{norm_y_max}]x[{norm_z_min},{norm_z_max}]\")\n",
    "\n",
    "print(\" \")\n",
    "print(\"prova normalizzazioni errori\")\n",
    "VVV = torch.rand((2,4), device=device)\n",
    "print(VVV - Norm_coords(Inv_Norm_coords(VVV)))\n",
    "print(VVV - Inv_Norm_coords(Norm_coords(VVV)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88684f9d-0987-484c-bb64-d3ff43e8c311",
   "metadata": {},
   "source": [
    "<h1>Sigma ML</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824a608b-243e-42c1-ae6a-4a416d84a2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sigmoid(value, sharpness=5.0, mu=factor_z/2*3.4):\n",
    "    return 1.0 / (1.0 + torch.exp(sharpness - mu * value))\n",
    "\n",
    "def generate_sigma_coords(n_points=PDE_batch_size):\n",
    "    t_coords = norm_t_min + (norm_t_max - norm_t_min) * torch.rand(n_points, 1, device=device)\n",
    "    x_coords = norm_x_min + (norm_x_max - norm_x_min) * torch.rand(n_points, 1, device=device)\n",
    "    y_coords = norm_y_min + (norm_y_max - norm_y_min) * torch.rand(n_points, 1, device=device)\n",
    "    z_coords = norm_z_min + (norm_z_max - norm_z_min) * torch.rand(n_points, 1, device=device)\n",
    "    points = torch.cat([t_coords, x_coords, y_coords, z_coords], dim=-1)\n",
    "    sigma_coords = torch.zeros_like(points[:, 0:1], device=device)\n",
    "    mask_top = points[:, 3] > Norm_z(z_max - (L - d) / 2)\n",
    "    mask_bottom = points[:, 3] < Norm_z(z_min + (L - d) / 2)\n",
    "    mask = mask_top | mask_bottom\n",
    "    sigma_coords[mask] = 1.0\n",
    "    z = points[:, 3].unsqueeze(-1)\n",
    "    sigmoid_top = get_sigmoid(torch.abs(z - Norm_z(z_max - (L - d) / 2)))\n",
    "    sigmoid_bottom = get_sigmoid(torch.abs(z - Norm_z(z_min + (L - d) / 2)))\n",
    "    sigma_coords = sigma_coords * sigmoid_top * sigmoid_bottom\n",
    "    return points, sigma_coords\n",
    "\n",
    "\n",
    "if flag_train_sigma == True:\n",
    "    # PLOTs\n",
    "    points, sigma_coords = generate_sigma_coords(10000)\n",
    "    # plane XZ\n",
    "    x_coords = Inv_Norm_x( points[:,1] )\n",
    "    z_coords = Inv_Norm_z( points[:,3] )\n",
    "    x_coords = x_coords.detach().cpu().numpy()\n",
    "    z_coords = z_coords.detach().cpu().numpy()\n",
    "    sigma_coords = sigma_coords.detach().cpu().numpy()\n",
    "    # plots\n",
    "    fig = plt.scatter(x_coords, z_coords, c=sigma_coords, s=2)\n",
    "    plt.title(\"Sigma values\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"z\")\n",
    "    plt.colorbar(fig)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.scatter( z_coords, sigma_coords, c=\"green\", s=1 )\n",
    "    plt.axvline(x=-d/2, color=\"red\", linestyle=\"--\", linewidth=1.5)\n",
    "    plt.axvline(x=d/2,  color=\"red\", linestyle=\"--\", linewidth=1.5)\n",
    "    plt.xlabel(\"z\")\n",
    "    plt.ylabel(\"V\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b710ad-a4ae-44de-b627-e966f32aa12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### SIGMA DNN model\n",
    "\n",
    "class DNN_model(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, n_nodes, n_layers, n_batches, dropout):\n",
    "        super().__init__()  \n",
    "        # DNN part\n",
    "        self.n_batches = n_batches\n",
    "        self.dropout = dropout\n",
    "        layers = [nn.Linear(input_dim, n_nodes), nn.ReLU(), nn.Dropout(self.dropout)]\n",
    "        for _ in range(n_layers - 1):\n",
    "            layers.append(nn.Linear(n_nodes, n_nodes))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(self.dropout))\n",
    "        layers.append(nn.Linear(n_nodes, 1))\n",
    "        layers.append(nn.ReLU())\n",
    "        self.network = nn.Sequential(*layers)\n",
    "        # Xavier initialization\n",
    "        for layer in self.network:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                init.xavier_normal_(layer.weight, gain=1.0)\n",
    "                init.zeros_(layer.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "  \n",
    "    def train_model(self, optimizer, loss_function, epochs=500, batch_size=4096, validation_split=0.1):\n",
    "        print(\"Training in progress...\")\n",
    "        start_time = time.time()\n",
    "        n_train_batches = int( (1 - validation_split) * self.n_batches)\n",
    "        n_val_batches   = self.n_batches - n_train_batches\n",
    "        print(f\"  number of epochs             : {epochs}\")\n",
    "        print(f\"  number of train batches      : {n_train_batches}\")\n",
    "        print(f\"  number of validation batches : {n_val_batches}\")\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=20)\n",
    "        history = []\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            start = time.time()\n",
    "            \n",
    "            # === TRAINING STEP ===\n",
    "            self.train()\n",
    "            start_data_tr = time.time()\n",
    "            data_total_loss = 0            \n",
    "            for indx_batch in range(n_train_batches):\n",
    "                optimizer.zero_grad()\n",
    "                data_coords, target = generate_sigma_coords(batch_size)\n",
    "                data_coords.requires_grad=True\n",
    "                predictions = self.forward(data_coords)\n",
    "                loss = loss_function( predictions, target )\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                data_total_loss += loss.item()\n",
    "            data_total_loss /= n_train_batches\n",
    "            end_data_tr = time.time()\n",
    "\n",
    "            # === VALIDATION STEP ===\n",
    "            self.eval()\n",
    "            start_val = time.time()\n",
    "            data_val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for indx_batch in range(n_val_batches):\n",
    "                    optimizer.zero_grad()\n",
    "                    data_coords, target = generate_sigma_coords(batch_size)\n",
    "                    data_coords.requires_grad=True\n",
    "                    predictions = self.forward(data_coords)\n",
    "                    loss = loss_function( predictions, target )\n",
    "                    data_val_loss += loss.item()\n",
    "                data_val_loss /= n_val_batches\n",
    "            end_val = time.time()\n",
    "            scheduler.step(data_val_loss)\n",
    "\n",
    "            end = time.time()\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - data loss: {data_total_loss} - val Loss: {data_val_loss}\")\n",
    "            print(f\"    time : {end - start} s  -  data: {end_data_tr - start_data_tr} s - val: {end_val - start_val} s\")\n",
    "            print(f\" \")\n",
    "            history.append([ data_total_loss, data_val_loss ])\n",
    "            if data_total_loss < 1e-7:\n",
    "                # save model\n",
    "                torch.save(self.state_dict(), \"sigma_model_plane3D-2.pth\")\n",
    "                print(f\"Done!  (time : {time.time() - start_time})\")\n",
    "                return history\n",
    "\n",
    "        # save model\n",
    "        torch.save(self.state_dict(), \"sigma_model_plane3D-2.pth\")\n",
    "        print(f\"Done!  (time : {time.time() - start_time})\")\n",
    "        return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9905710-b90a-4740-af2d-96e31d72ba15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# construction and training of DNN SIGMA\n",
    "input_dim = 4     # (t, x, y, z)\n",
    "n_nodes = 64\n",
    "n_layers = 5\n",
    "n_batches = 96\n",
    "dropout = 0\n",
    "sigma_model = DNN_model( input_dim, n_nodes, n_layers, n_batches, dropout ).to(device)\n",
    "\n",
    "if flag_train_sigma == True:\n",
    "    optimizer = torch.optim.Adam(sigma_model.parameters(), lr=0.001, weight_decay=1e-8)\n",
    "    loss_function = nn.MSELoss()\n",
    "    history_sigma = sigma_model.train_model(optimizer, loss_function, epochs=400)\n",
    "    print(sigma_model)\n",
    "    \n",
    "    # history of training\n",
    "    plt.plot([pair[0] for pair in history_sigma], label=\"Training\")\n",
    "    plt.plot([pair[1] for pair in history_sigma], label=\"Validation\")\n",
    "    plt.legend(title=\"Error\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"MSE\")\n",
    "    plt.grid(alpha=0.2)\n",
    "    plt.yscale(\"log\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cff98d1-3131-4f65-8b3b-845a729392d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if flag_train_sigma == False:\n",
    "    sigma_model.load_state_dict(torch.load(\"sigma_model_plane3D-2.pth\"))\n",
    "sigma_model.eval()\n",
    "\n",
    "sampled_times = np.linspace(Norm_time(t_min), Norm_time(t_max), 6)\n",
    "sampled_y = Norm_y( (y_max + y_min) / 2 )\n",
    "\n",
    "n_samples = 10000\n",
    "if flag_train_sigma == True:\n",
    "    plt.figure(figsize=(16,10))\n",
    "else:\n",
    "    plt.figure(figsize=(16,4))\n",
    "\n",
    "for i_plot, n_t in enumerate(sampled_times, 1):\n",
    "    real_t = Inv_Norm_time(n_t)\n",
    "    X_pred, sigma_true = generate_sigma_coords(n_samples)\n",
    "    X_pred[:,0] = n_t * torch.ones_like( X_pred[:,0], device=device )\n",
    "    X_pred[:,2] = sampled_y * torch.ones_like( X_pred[:,2], device=device )\n",
    "    X = X_pred.detach().cpu().numpy()\n",
    "    \n",
    "    # predicted result\n",
    "    with torch.no_grad():\n",
    "        sigma_pred = sigma_model.forward(X_pred)\n",
    "    sigma_pred = sigma_pred.detach().cpu().numpy()\n",
    "\n",
    "    if flag_train_sigma == True:\n",
    "        # true result\n",
    "        sigma_true = sigma_true.detach().cpu().numpy()\n",
    "        \n",
    "        plt.subplot(3, len(sampled_times), i_plot)\n",
    "        plt.title(f\"Pred {real_t:3f} ns\")\n",
    "        im0=plt.scatter(Inv_Norm_x(X[:, 1]), Inv_Norm_z(X[:, 3]), c=sigma_pred, s=2)\n",
    "        plt.colorbar(im0)\n",
    "        \n",
    "        plt.subplot(3, len(sampled_times), len(sampled_times) + i_plot)\n",
    "        plt.title(f\"True {real_t:3f} ns\")\n",
    "        im1=plt.scatter(Inv_Norm_x(X[:, 1]), Inv_Norm_z(X[:, 3]), c=sigma_true, s=2)\n",
    "        plt.colorbar(im1)\n",
    "    \n",
    "        plt.subplot(3, len(sampled_times), 2*len(sampled_times) + i_plot)\n",
    "        plt.title(f\"Error {real_t:3f} ns\")\n",
    "        im2=plt.scatter(Inv_Norm_x(X[:, 1]), Inv_Norm_z(X[:, 3]), c=np.abs(sigma_true-sigma_pred), s=2)\n",
    "        plt.colorbar(im2)\n",
    "        \n",
    "    else:\n",
    "        plt.subplot(1, len(sampled_times), i_plot)\n",
    "        plt.title(f\"Sigma (t={real_t:3f} ns)\")\n",
    "        im0=plt.scatter(Inv_Norm_x(X[:, 1]), Inv_Norm_z(X[:, 3]), c=sigma_pred, s=2)\n",
    "        plt.colorbar(im0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"plot_c-2_sigma.jpg\", format=\"jpg\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "sigma_model.eval()\n",
    "n_points = 10000\n",
    "t_coords = norm_t_min * torch.ones(n_points, 1, device=device)\n",
    "x_coords = norm_x_min * torch.ones(n_points, 1, device=device)\n",
    "y_coords = norm_y_min * torch.ones(n_points, 1, device=device)\n",
    "z_coords = norm_z_min + (norm_z_max - norm_z_min) * torch.rand(n_points, 1, device=device)\n",
    "coords_sample = torch.cat( [t_coords, x_coords, y_coords, z_coords], dim=-1 )\n",
    "sigma_sample  = sigma_model( coords_sample )\n",
    "z_coords = z_coords.detach().cpu().numpy()\n",
    "sigma_sample = sigma_sample.detach().cpu().numpy()\n",
    "plt.scatter( Inv_Norm_z(z_coords), sigma_sample, c=\"green\", s=1 )\n",
    "plt.xlabel(\"z\")\n",
    "plt.ylabel(\"sigma values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549aa6d2-6022-4c0e-8d4b-69f01dd8aa80",
   "metadata": {},
   "source": [
    "<h1>PINN</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f91aad-d986-47b8-b937-fc2f12f29b4e",
   "metadata": {},
   "source": [
    "<h3>Initial conditions</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df49d53e-44b4-4659-8c71-645de46c70da",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_model.eval()\n",
    "\n",
    "def gen_IC_points(model=None, batch_size=IC_batch_size, oversample_factor=4):\n",
    "    # Oversample\n",
    "    M = batch_size * oversample_factor\n",
    "    t_coords = norm_t_min * torch.ones(M, 1, device=device)  # initial time\n",
    "    x_coords = norm_x_min + (norm_x_max - norm_x_min) * torch.rand(M, 1, device=device)\n",
    "    y_coords = norm_y_min + (norm_y_max - norm_y_min) * torch.rand(M, 1, device=device)\n",
    "    z_coords = norm_z_min + (norm_z_max - norm_z_min) * torch.rand(M, 1, device=device)\n",
    "    coords = torch.cat([t_coords, x_coords, y_coords, z_coords], dim=-1)\n",
    "    z_factor = (z_coords - norm_z_min) / (norm_z_max - norm_z_min)\n",
    "    V_target = V0 * z_factor\n",
    "    # Importance sampling if model is not None\n",
    "    if model is not None:\n",
    "        coords.requires_grad=True\n",
    "        V_pred = model(coords)\n",
    "        grads = torch.autograd.grad(\n",
    "            V_pred, coords,\n",
    "            grad_outputs=torch.ones_like(V_pred),\n",
    "            create_graph=False, retain_graph=False\n",
    "        )[0]\n",
    "        E_pred = ( (grads[:,1].unsqueeze(-1)/factor_x)**2 \\\n",
    "                + (grads[:,2].unsqueeze(-1)/factor_y)**2 \\\n",
    "                + (grads[:,3].unsqueeze(-1)/factor_z)**2 ) ** (1/2)\n",
    "        weights = torch.abs(V_pred - V_target) + 10*torch.abs(E_pred - E0*torch.ones_like(E_pred)) + 1\n",
    "        weights = torch.clamp(weights.squeeze(-1), min=1e-12)\n",
    "        probs = weights / torch.sum(weights)\n",
    "        # Resampling\n",
    "        idx = torch.multinomial(probs, batch_size, replacement=False)\n",
    "        coords_batch = coords[idx]\n",
    "        values_batch = V_target[idx]\n",
    "    else:\n",
    "        # uniform sampling if model is None\n",
    "        coords_batch = coords[:batch_size]\n",
    "        values_batch = V_target[:batch_size]\n",
    "    #\n",
    "    return coords_batch.detach(), values_batch.detach()\n",
    "\n",
    "\n",
    "def compute_IC_loss(model, n_points=IC_batch_size, loss_function=nn.MSELoss()):\n",
    "    coords, values = gen_IC_points(model=model, batch_size=n_points)\n",
    "    coords.requires_grad = True\n",
    "    # IC loss wrt V\n",
    "    values_pred = model.forward(coords)\n",
    "    loss = loss_function( values_pred, values )\n",
    "    # IC loss wrt E\n",
    "    E_pred = ( (model._PDE.get_derivative(values_pred, coords, 1)[:,1].unsqueeze(-1)/factor_x)**2 \\\n",
    "                + (model._PDE.get_derivative(values_pred, coords, 1)[:,2].unsqueeze(-1)/factor_y)**2 \\\n",
    "                + (model._PDE.get_derivative(values_pred, coords, 1)[:,3].unsqueeze(-1)/factor_z)**2 ) ** (1/2)\n",
    "    E_true = E0 * torch.ones_like(E_pred, device=device)\n",
    "    loss += 1e4 * loss_function(E_pred, E_true)\n",
    "    return loss\n",
    "    \n",
    "\n",
    "# PLOTs\n",
    "points, IC_values = gen_IC_points(batch_size=10000)\n",
    "print(f\"initial time : {Inv_Norm_time(np.unique(points[:len(points)//2,0].detach().cpu().numpy()))}\")\n",
    "# plane XZ\n",
    "x_coords = Inv_Norm_x( points[:,1] )\n",
    "z_coords = Inv_Norm_z( points[:,3] )\n",
    "x_coords = x_coords.detach().cpu().numpy()\n",
    "z_coords = z_coords.detach().cpu().numpy()\n",
    "IC_values = IC_values.detach().cpu().numpy()\n",
    "# plots\n",
    "fig = plt.scatter(x_coords, z_coords, c=IC_values, s=1)\n",
    "plt.title(\"Initial condition\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"z\")\n",
    "plt.colorbar(fig)\n",
    "plt.show()\n",
    "\n",
    "fig = plt.scatter(z_coords, IC_values, s=1, c=\"blue\")\n",
    "plt.title(\"Initial condition\")\n",
    "plt.xlabel(\"z\")\n",
    "plt.ylabel(\"V\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e072119c-f1a1-40b4-869c-c4077669783c",
   "metadata": {},
   "source": [
    "<h3>Boundary condition</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc96ac4-3cc3-4dc5-9d5c-fa8b6b8a37c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_BC_points(n_points=BC_batch_size):\n",
    "    # minimum z-coord\n",
    "    t_coords = norm_t_min + (norm_t_max - norm_t_min) * torch.rand(n_points, 1, device=device)\n",
    "    x_coords = norm_x_min + (norm_x_max - norm_x_min) * torch.rand(n_points, 1, device=device)\n",
    "    y_coords = norm_y_min + (norm_y_max - norm_y_min) * torch.rand(n_points, 1, device=device)\n",
    "    z_coords = norm_z_min * torch.ones(n_points, 1, device=device)       \n",
    "    points2 = torch.cat( [t_coords, x_coords, y_coords, z_coords], dim=-1 )\n",
    "    values2 = 0 * torch.ones_like( t_coords, device=device )\n",
    "    # maximum z-coord\n",
    "    t_coords = norm_t_min + (norm_t_max - norm_t_min) * torch.rand(n_points, 1, device=device)\n",
    "    x_coords = norm_x_min + (norm_x_max - norm_x_min) * torch.rand(n_points, 1, device=device)\n",
    "    y_coords = norm_y_min + (norm_y_max - norm_y_min) * torch.rand(n_points, 1, device=device)\n",
    "    z_coords = norm_z_max * torch.ones(n_points, 1, device=device)       \n",
    "    points3 = torch.cat( [t_coords, x_coords, y_coords, z_coords], dim=-1 )\n",
    "    values3 = V0 * torch.ones_like( t_coords, device=device )\n",
    "    #\n",
    "    return torch.cat( [points2, points3], dim=0 ), torch.cat( [values2, values3], dim=0 )\n",
    "\n",
    "def compute_BC_loss(model, n_points=BC_batch_size, loss_function=nn.MSELoss()):\n",
    "    coords, values = gen_BC_points(n_points)\n",
    "    coords.requires_grad = True\n",
    "    values_pred = model.forward(coords)\n",
    "    loss = loss_function( values_pred, values )\n",
    "    return loss\n",
    "    \n",
    "\n",
    "# PLOT BC\n",
    "points, BC_values = gen_BC_points(10000)\n",
    "z_coords = Inv_Norm_z( points[:,3] )\n",
    "z_coords = z_coords.detach().cpu().numpy()\n",
    "BC_values = BC_values.detach().cpu().numpy()\n",
    "fig = plt.scatter(z_coords, BC_values, s=3, c=\"blue\")\n",
    "plt.title(\"Boundary condition\")\n",
    "plt.xlabel(\"z\")\n",
    "plt.ylabel(\"V\")\n",
    "plt.colorbar(fig)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95986bf5-dea9-40de-ae9f-72172e79b8b9",
   "metadata": {},
   "source": [
    "<h3>PDE</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d5a229-8a6f-421d-9c47-2dc5210ef832",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QSM_PDE:\n",
    "       \n",
    "    def compute_PDE(self, coords, pred_func, flag=False):\n",
    "        sigma_model.eval()\n",
    "        sigma_comp = sigma_model.forward(coords)\n",
    "        u = pred_func[:,0].unsqueeze(-1)\n",
    "        u_x  = self.get_derivative(pred_func, coords, 1)[:,1].unsqueeze(-1) / factor_x\n",
    "        u_xx = self.get_derivative(u_x, coords, 1)[:,1].unsqueeze(-1) / factor_x\n",
    "        u_y  = self.get_derivative(pred_func, coords, 1)[:,2].unsqueeze(-1) / factor_y\n",
    "        u_yy = self.get_derivative(u_y, coords, 1)[:,2].unsqueeze(-1) / factor_y\n",
    "        u_z  = self.get_derivative(pred_func, coords, 1)[:,3].unsqueeze(-1) / factor_z\n",
    "        u_zz = self.get_derivative(u_z, coords, 1)[:,3].unsqueeze(-1) / factor_z\n",
    "        Delta_u = u_xx + u_yy + u_zz\n",
    "        Delta_u_t = self.get_derivative(Delta_u, coords, 1)[:,0].unsqueeze(-1)\n",
    "        div_sigma_grad_u =  self.get_derivative(sigma_comp, coords, 1)[:,1].unsqueeze(-1) * u_x / factor_x \\\n",
    "                                + sigma_comp * self.get_derivative(u_x, coords, 1)[:,1].unsqueeze(-1) / factor_x \\\n",
    "                          + self.get_derivative(sigma_comp, coords, 1)[:,2].unsqueeze(-1) * u_y / factor_y \\\n",
    "                                + sigma_comp * self.get_derivative(u_y, coords, 1)[:,2].unsqueeze(-1) / factor_y \\\n",
    "                          + self.get_derivative(sigma_comp, coords, 1)[:,3].unsqueeze(-1) * u_z / factor_z \\\n",
    "                                + sigma_comp * self.get_derivative(u_z, coords, 1)[:,3].unsqueeze(-1) / factor_z\n",
    "        # equation\n",
    "        factorrr = torch.exp(coords[:,0].unsqueeze(-1) * factor_logt) * factor_logt\n",
    "        P1 = Delta_u_t / factorrr\n",
    "        P2 = div_sigma_grad_u\n",
    "        eq = P1 + P2\n",
    "        if flag == True:\n",
    "            u_t = self.get_derivative(u, coords, 1)[:,0] / factorrr\n",
    "            print(f\"u_t in [{(u_t).min()}, {(u_t).max()}] , mean = {torch.mean((u_t))}\")\n",
    "            print(f\"Eps in [{(P1).min()}, {(P1).max()}] , mean = {torch.mean((P1))}\")\n",
    "            print(f\"Div in [{(P2).min()}, {(P2).max()}] , mean = {torch.mean((P2))}\")\n",
    "            print(f\"Eq  in [{(eq).min()}, {(eq).max()}] , mean = {torch.mean((eq))}\")\n",
    "            print(\" \")\n",
    "        return eq.squeeze(-1)*1e3, P1.squeeze(-1)*1e3, P2.squeeze(-1)*1e3\n",
    "\n",
    "        \n",
    "    def gen_PDE_points(self, model, batch_size=PDE_batch_size, oversample_factor=5):\n",
    "        # Oversample\n",
    "        M = batch_size * oversample_factor\n",
    "        t_coords = norm_t_min + (norm_t_max - norm_t_min) * torch.rand(M, 1, device=device)\n",
    "        x_coords = norm_x_min + (norm_x_max - norm_x_min) * torch.rand(M, 1, device=device)\n",
    "        y_coords = norm_y_min + (norm_y_max - norm_y_min) * torch.rand(M, 1, device=device)\n",
    "        z_coords = norm_z_min + (norm_z_max - norm_z_min) * torch.rand(M, 1, device=device)\n",
    "        coords = torch.cat([t_coords, x_coords, y_coords, z_coords], dim=-1)\n",
    "        coords.requires_grad=True\n",
    "        V_pred = model(coords)\n",
    "        grads = torch.autograd.grad(\n",
    "            V_pred, coords,\n",
    "            grad_outputs=torch.ones_like(V_pred),\n",
    "            create_graph=False, retain_graph=False\n",
    "        )[0]\n",
    "        dV_dt = grads[:, 0:1]\n",
    "        dV_dx = grads[:, 1:]\n",
    "        grad_norm = torch.norm(dV_dx, dim=1, keepdim=True)\n",
    "        # Importance sampling\n",
    "        weights = ( grad_norm**2 + 5 * dV_dt**2 ) ** 0.5 + torch.abs( V_pred ) + 10\n",
    "        weights = weights.squeeze(-1)\n",
    "        weights = torch.clamp(weights, min=1e-12)\n",
    "        probs = weights / torch.sum(weights)\n",
    "        # Resampling\n",
    "        idx = torch.multinomial(probs, batch_size, replacement=False)\n",
    "        coords_batch = coords[idx]\n",
    "        return coords_batch.detach()\n",
    "\n",
    "    \n",
    "    def get_derivative(self, y, x, n: int = 1):\n",
    "        if n == 0:\n",
    "            return y\n",
    "        else:\n",
    "            dy_dx = torch.autograd.grad(y, x, torch.ones_like(y).to(y.device), create_graph=True, retain_graph=True, allow_unused=True)[0]              \n",
    "        return self.get_derivative(dy_dx, x, n - 1)\n",
    "\n",
    "\n",
    "    def compute_PDE_loss(self, model, n_points=PDE_batch_size, loss_function=nn.MSELoss(), flag=False):\n",
    "        coords = self.gen_PDE_points(model=model, batch_size=n_points)\n",
    "        coords.requires_grad = True\n",
    "        values_pred = model.forward(coords)\n",
    "        pde_pred, _, _ = self.compute_PDE(coords, values_pred, flag=flag)\n",
    "        loss = loss_function( pde_pred, torch.zeros_like(pde_pred, dtype=torch.float32, device=device) )\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b6cc6c-9b13-42f3-b016-304df70a465f",
   "metadata": {},
   "source": [
    "<h3>PINN model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb3a5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfScaledTanh(nn.Module):\n",
    "    def __init__(self, size, init_beta=0.0):\n",
    "        super().__init__()\n",
    "        self.beta = nn.Parameter(torch.full((size,), init_beta, dtype=torch.float32))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.tanh(x) + self.beta * x * torch.tanh(x)\n",
    "    \n",
    "\n",
    "class PINN_model(nn.Module):\n",
    "    def __init__(self, input_dim, n_nodes, n_layers, n_batches, dropout):\n",
    "        super().__init__()\n",
    "        self.n_batches = n_batches\n",
    "        self.dropout = dropout\n",
    "        validation_split = 0.1\n",
    "        self.n_train_batches = int((1 - validation_split) * self.n_batches)\n",
    "        self.n_val_batches = self.n_batches - self.n_train_batches\n",
    "        self.n_layers = n_layers\n",
    "        self.n_nodes = n_nodes\n",
    "        self.history = []\n",
    "        self.optimizer = 0\n",
    "        self.total_time = 0\n",
    "        self._PDE = QSM_PDE()\n",
    "        # ==== LAYERS ====\n",
    "        self.input_layer = nn.Linear(input_dim, n_nodes)\n",
    "        self.initial_activation = SelfScaledTanh(n_nodes)\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for _ in range(n_layers - 1):\n",
    "            self.hidden_layers.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(n_nodes, n_nodes),\n",
    "                    SelfScaledTanh(n_nodes),\n",
    "                    nn.Dropout(self.dropout)\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.output_layer = nn.Linear(n_nodes, 1)\n",
    "        self.final_activation = SelfScaledTanh(1)\n",
    "\n",
    "    \n",
    "    def forward(self, coords):\n",
    "        x = self.initial_activation(self.input_layer(coords))\n",
    "        residual = x\n",
    "        for i, layer in enumerate(self.hidden_layers):\n",
    "            out = layer(x)\n",
    "            if i % 2 == 1:\n",
    "                x = out + residual\n",
    "                residual = x\n",
    "            else:\n",
    "                x = out\n",
    "        x = self.output_layer(x)\n",
    "        return self.final_activation(x)\n",
    "        \n",
    "    \n",
    "    def train_model(\n",
    "        self, \n",
    "        optimizer, \n",
    "        patience = 20, \n",
    "        factor_scheduler = 0.98, \n",
    "        loss_function = nn.MSELoss(), \n",
    "        epochs = 2000, \n",
    "        flag_plot_PDE = 20, \n",
    "        flag_plot = 100,\n",
    "        flag_losses = 1,\n",
    "        flag_checkpoint = 500\n",
    "    ):\n",
    "        print(\"Start :\")\n",
    "        start_time = time.time()   \n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=factor_scheduler, patience=patience)\n",
    "        self.history = []\n",
    "        self.optimizer = optimizer\n",
    "        # number of batches for training and validation\n",
    "        print(f\"  number of epochs             : {epochs}\")\n",
    "        print(f\"  number of train batches      : {self.n_train_batches}\")\n",
    "        print(f\"  number of validation batches : {self.n_val_batches}\")\n",
    "        print(\" \")        \n",
    "        print(\"Training in progress...\")\n",
    "        print(\" \")\n",
    "        n_train_batches = self.n_train_batches\n",
    "        n_val_batches = self.n_val_batches\n",
    "\n",
    "        weight_IC, weight_BC, weight_PDE = 1, 1, 1e-1\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            start = time.time()\n",
    "            \n",
    "            # === TRAINING STEP ===\n",
    "            self.train()\n",
    "            start_tr = time.time()\n",
    "            IC_total_loss, BC_total_loss, PDE_total_loss = 0, 0, 0            \n",
    "            for indx_batch in range(n_train_batches):\n",
    "                optimizer.zero_grad()\n",
    "                IC_loss  = compute_IC_loss(model=self)\n",
    "                BC_loss  = compute_BC_loss(model=self)\n",
    "                if epoch % flag_plot_PDE == 0 and indx_batch == n_train_batches - 1:\n",
    "                    PDE_loss = self._PDE.compute_PDE_loss(model=self, flag=True )\n",
    "                else:\n",
    "                    PDE_loss = self._PDE.compute_PDE_loss(model=self, flag=False)\n",
    "                Loss = weight_IC * IC_loss + weight_BC * BC_loss + weight_PDE * PDE_loss\n",
    "                Loss.backward()\n",
    "                optimizer.step()\n",
    "                IC_total_loss   += IC_loss.item()\n",
    "                BC_total_loss   += BC_loss.item()\n",
    "                PDE_total_loss  += PDE_loss.item()\n",
    "            IC_total_loss  /= n_train_batches\n",
    "            BC_total_loss  /= n_train_batches\n",
    "            PDE_total_loss /= n_train_batches\n",
    "            end_tr = time.time()\n",
    "\n",
    "            # === VALIDATION STEP ===\n",
    "            self.eval()\n",
    "            start_val = time.time()\n",
    "            IC_val_loss, BC_val_loss, PDE_val_loss = 0, 0, 0  \n",
    "            for indx_batch in range(n_val_batches):\n",
    "                optimizer.zero_grad()\n",
    "                IC_val_loss  += (compute_IC_loss(model=self) ).item()\n",
    "                BC_val_loss  += ( compute_BC_loss(model=self) ).item()\n",
    "                PDE_val_loss += ( self._PDE.compute_PDE_loss(model=self) ).item()\n",
    "            IC_val_loss   /= n_val_batches\n",
    "            BC_val_loss   /= n_val_batches\n",
    "            PDE_val_loss  /= n_val_batches\n",
    "            scheduler.step( weight_IC * IC_val_loss + weight_BC * BC_val_loss + weight_PDE * PDE_val_loss )\n",
    "            end_val = time.time()\n",
    "            \n",
    "            end = time.time()\n",
    "\n",
    "            \n",
    "            lambda_eff = weight_PDE/weight_IC * PDE_total_loss/IC_total_loss\n",
    "            current_lr = self.optimizer.param_groups[0]['lr']\n",
    "            if (epoch+1) % flag_losses == 0:\n",
    "                # === PRINT LOSSES ===\n",
    "                print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "                print(f\"  Training losses   ==>  IC: {IC_total_loss} - BC: {BC_total_loss} - pde: {PDE_total_loss}\")\n",
    "                print(f\"  Validation losses ==>  IC: {IC_val_loss} - BC: {BC_val_loss} - pde: {PDE_val_loss}\")\n",
    "                print(f\"  time : {end - start} s  - train: {end_tr - start_tr} s  - val: {end_val - start_val} s\")\n",
    "                print(f\"     ( w_IC : {weight_IC} - w_BC : {weight_BC} - w_PDE : {weight_PDE} - lambda_eff : {lambda_eff} )\")\n",
    "                print(f\"     ( learning rate : {current_lr})\")\n",
    "                print(f\" \")\n",
    "                print(f\" \")\n",
    "            self.history.append([ IC_total_loss, PDE_total_loss, IC_val_loss, PDE_val_loss,\n",
    "                            weight_IC, weight_PDE, lambda_eff, current_lr, BC_total_loss, BC_val_loss, weight_BC, 0 ])\n",
    "\n",
    "\n",
    "\n",
    "            # PLOT\n",
    "            if epoch % flag_plot == 0:\n",
    "                \n",
    "                sampled_times = Norm_time( t_min + np.array([ 0, 0.1, 0.2, 0.3, 0.7, 1 ]) * (t_max - t_min) )\n",
    "                n_samples = 20000\n",
    "                plt.figure(figsize=(16,14))\n",
    "                for i_plot, n_t in enumerate(sampled_times, 1):\n",
    "                    real_t = Inv_Norm_time(n_t)\n",
    "                    X_pred = self._PDE.gen_PDE_points(self, batch_size=n_samples)\n",
    "                    X_pred[:,0] = n_t * torch.ones_like(X_pred[:,0], device=device)\n",
    "                    X_Sample = X_pred.detach().cpu().numpy()\n",
    "                    X_pred.requires_grad=True\n",
    "                    V_pred = self.forward(X_pred)\n",
    "                    \n",
    "                    E_pred = ( (self._PDE.get_derivative(V_pred, X_pred, 1)[:,1].unsqueeze(-1)/factor_x)**2 \\\n",
    "                            + (self._PDE.get_derivative(V_pred, X_pred, 1)[:,2].unsqueeze(-1)/factor_y)**2 \\\n",
    "                            + (self._PDE.get_derivative(V_pred, X_pred, 1)[:,3].unsqueeze(-1)/factor_z)**2 ) ** (1/2)\n",
    "                    V_pred = V_pred.detach().cpu().numpy()\n",
    "                    E_pred = E_pred.detach().cpu().numpy()\n",
    "\n",
    "                    v_min = 0\n",
    "                    v_max = V0\n",
    "                    \n",
    "                    # ====== VOLT ======\n",
    "                    plt.subplot(4, len(sampled_times), i_plot)\n",
    "                    im0=plt.scatter(Inv_Norm_x(X_Sample[:, 1]), Inv_Norm_z(X_Sample[:, 3]), c=V_pred, s=2, cmap='plasma', vmin=v_min, vmax=v_max)\n",
    "                    x_vals = x_min + (x_max - x_min) * np.random.rand(1000)\n",
    "                    z_val  = z_max - L/2 + d/2\n",
    "                    plt.scatter(x_vals, np.full_like(x_vals, z_val), c=\"red\", s=1)\n",
    "                    z_val  = z_min+L/2 - d/2\n",
    "                    plt.scatter(x_vals, np.full_like(x_vals, z_val), c=\"red\", s=1)\n",
    "                    plt.title(f\"V(t={real_t:.2f} ns)\")\n",
    "                    plt.xlabel(\"x coordinate [$\\\\mu$m]\")\n",
    "                    if i_plot == 1:\n",
    "                        plt.ylabel(\"z coordinate [$\\\\mu$m]\")\n",
    "                    plt.xlim(x_min, x_max)\n",
    "                    plt.ylim(z_min, z_max)\n",
    "                    plt.colorbar(im0)\n",
    "                    plt.tight_layout()\n",
    "                    \n",
    "                    # ====== VOLT UNIDIM ======\n",
    "                    plt.subplot(4, len(sampled_times), len(sampled_times) + i_plot)\n",
    "                    im2=plt.scatter(Inv_Norm_z(X_Sample[:, 3]), V_pred, s=1)\n",
    "                    plt.title(f\"t = {real_t:.2f} ns\")\n",
    "                    if i_plot == 1:\n",
    "                        plt.ylabel(\"Potential [V]\")\n",
    "                    plt.xlabel(\"z coordinate [$\\\\mu$m]\")\n",
    "                    plt.tight_layout()\n",
    "\n",
    "                    # ====== ELECTRIC ======\n",
    "                    v_min = 0\n",
    "                    v_max = (V0 - 0) / ( norm_z_max - norm_z_min ) / factor_z\n",
    "                    plt.subplot(4, len(sampled_times), 2*len(sampled_times) + i_plot)\n",
    "                    im1=plt.scatter(Inv_Norm_x(X_Sample[:, 1]), Inv_Norm_z(X_Sample[:, 3]), c=E_pred, s=2, cmap='plasma', vmin=0, vmax=0.05)\n",
    "                    x_vals = x_min + (x_max - x_min) * np.random.rand(1000)\n",
    "                    z_val  = z_max - L/2 + d/2\n",
    "                    plt.scatter(x_vals, np.full_like(x_vals, z_val), c=\"red\", s=1)\n",
    "                    z_val  = z_min + L/2 - d/2\n",
    "                    plt.scatter(x_vals, np.full_like(x_vals, z_val), c=\"red\", s=1)\n",
    "                    plt.title(f\"E(t={real_t:.2f} ns)\")\n",
    "                    plt.xlabel(\"x coordinate [$\\\\mu$m]\")\n",
    "                    if i_plot == 1:\n",
    "                        plt.ylabel(\"z coordinate [$\\\\mu$m]\")\n",
    "                    plt.xlim(x_min, x_max)\n",
    "                    plt.ylim(z_min, z_max)\n",
    "                    plt.colorbar(im1)\n",
    "                    plt.tight_layout()\n",
    "\n",
    "                    # ====== ELECTRIC UNIDIM ======\n",
    "                    plt.subplot(4, len(sampled_times), 3*len(sampled_times) + i_plot)\n",
    "                    im3=plt.scatter(Inv_Norm_z(X_Sample[:, 3]), E_pred, s=1)\n",
    "                    plt.ylim(0,0.06)\n",
    "                    plt.title(f\"t = {real_t:.2f} ns\")\n",
    "                    if i_plot == 1:\n",
    "                        plt.ylabel(\"Electric field [V/$\\\\mu$m]\")\n",
    "                    plt.xlabel(\"z coordinate [$\\\\mu$m]\")\n",
    "                    plt.tight_layout()\n",
    "                namee = f\"plot_c-2_pred_temp_{epoch}.jpg\"\n",
    "                plt.savefig(namee, format=\"jpg\", dpi=300)\n",
    "                plt.show()\n",
    "\n",
    "            # === CHECKPOINT ===\n",
    "            if (epoch) % flag_checkpoint == 0 and epoch>0:\n",
    "                checkpoint_path = f\"checkpoint_c-2_epoch_{epoch}.pth\"\n",
    "                torch.save({\n",
    "                    'n_nodes': self.n_nodes,\n",
    "                    'n_layers': self.n_layers,\n",
    "                    'epoch': epoch + 1,\n",
    "                    'model_state_dict': self.state_dict(),\n",
    "                    'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                    'history': self.history\n",
    "                }, checkpoint_path)\n",
    "\n",
    "        # END EPOCHS\n",
    "        self.history = torch.stack([torch.tensor(h) for h in self.history]).detach().cpu().numpy()\n",
    "        print(f\"Done!  (time : {time.time() - start_time})\")\n",
    "        return self.history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef06a56-e03e-41d7-a1d9-4e514741ae17",
   "metadata": {},
   "source": [
    "<h3>Training</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adab1247-b1c3-41c8-8e27-3721eebcfbd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### construction of PINN\n",
    "model = 0\n",
    "model = PINN_model( \n",
    "    input_dim = 4,  # (t, x, y, z)\n",
    "    n_nodes = 128, \n",
    "    n_layers = 6,\n",
    "    n_batches = 32,\n",
    "    dropout = 0 \n",
    ").to(device)\n",
    "\n",
    "# training\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.003, weight_decay=1e-9)\n",
    "loss_function = nn.MSELoss()\n",
    "model.train_model(\n",
    "    optimizer, \n",
    "    patience = 20, \n",
    "    factor_scheduler = 0.98,\n",
    "    loss_function = loss_function, \n",
    "    epochs = 10000,\n",
    "    flag_plot_PDE = 500, \n",
    "    flag_plot = 500,\n",
    "    flag_losses = 500,\n",
    "    flag_checkpoint = 1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd37450",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = f\"model-c3D-2.pth\"\n",
    "torch.save({\n",
    "    'n_nodes': model.n_nodes,\n",
    "    'n_layers': model.n_layers,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': model.optimizer.state_dict(),\n",
    "    'history': model.history\n",
    "}, checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9de61fb-0f44-4d56-b82d-11bc54737cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 4     # (t, x, y, z)\n",
    "n_nodes = 128\n",
    "n_layers = 6\n",
    "n_batches = 32\n",
    "dropout = 0\n",
    "model = PINN_model( input_dim, n_nodes, n_layers, n_batches, dropout ).to(device)\n",
    "checkpoint = torch.load(\"model-c3D-2.pth\", map_location=device, weights_only=False)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "sampled_times = Norm_time( t_min + np.array([ 0, 0.1, 0.2, 0.3, 0.7, 1 ]) * (t_max - t_min) )\n",
    "n_samples = 100000\n",
    "model.eval()\n",
    "sigma_model.eval()\n",
    "pde_class = QSM_PDE()\n",
    "\n",
    "x_coords = norm_x_min + (norm_x_max - norm_x_min) * torch.rand(n_samples, 1, device=device)\n",
    "y_coords = norm_y_min + (norm_y_max - norm_y_min) * torch.rand(n_samples, 1, device=device)\n",
    "z_coords = norm_z_min + (norm_z_max - norm_z_min) * torch.rand(n_samples, 1, device=device)\n",
    "\n",
    "n_plot = 2\n",
    "v_min = 0\n",
    "v_max = V0\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "# --- plane x=-300 ---\n",
    "for i_plot, n_t in enumerate(sampled_times, 1):\n",
    "    real_t = Inv_Norm_time(n_t)\n",
    "    X_pred = torch.cat([\n",
    "        n_t * torch.ones_like(x_coords, device=device),\n",
    "        Norm_x( -300 * torch.ones_like(x_coords, device=device) ),\n",
    "        y_coords,\n",
    "        z_coords\n",
    "    ], dim=-1)\n",
    "    X_Sample = X_pred.detach().cpu().numpy()\n",
    "    X_pred.requires_grad=True\n",
    "    V_pred = model.forward(X_pred)\n",
    "    E_pred = ( (pde_class.get_derivative(V_pred, X_pred, 1)[:,1].unsqueeze(-1)/factor_x)**2 \\\n",
    "              + (pde_class.get_derivative(V_pred, X_pred, 1)[:,2].unsqueeze(-1)/factor_y)**2 \\\n",
    "              + (pde_class.get_derivative(V_pred, X_pred, 1)[:,3].unsqueeze(-1)/factor_z)**2 ) ** (1/2)\n",
    "    V_pred = V_pred.detach().cpu().numpy()\n",
    "    E_pred = E_pred.detach().cpu().numpy()\n",
    "    # ====== V ======\n",
    "    plt.subplot(n_plot, len(sampled_times), i_plot)\n",
    "    im0=plt.scatter(Inv_Norm_y(X_Sample[:, 2]), Inv_Norm_z(X_Sample[:, 3]), c=V_pred, s=2, cmap='plasma', vmin=v_min, vmax=v_max)\n",
    "    x_vals = x_min + (x_max - x_min) * np.random.rand(1000)\n",
    "    z_val  = z_max - L/2 + d/2\n",
    "    plt.scatter(x_vals, np.full_like(x_vals, z_val), c=\"red\", s=1)\n",
    "    z_val  = z_min+L/2 - d/2\n",
    "    plt.scatter(x_vals, np.full_like(x_vals, z_val), c=\"red\", s=1)\n",
    "    plt.title(f\"V(t={real_t:.2f} ns)\")\n",
    "    plt.xlabel(\"y coordinate [$\\\\mu$m]\")\n",
    "    if i_plot == 1:\n",
    "        plt.ylabel(\"z coordinate [$\\\\mu$m]\")\n",
    "    plt.xlim(y_min, y_max)\n",
    "    plt.ylim(z_min, z_max)\n",
    "    plt.colorbar(im0)\n",
    "    plt.tight_layout()\n",
    "    # ====== E ======\n",
    "    plt.subplot(n_plot, len(sampled_times), len(sampled_times) + i_plot)\n",
    "    im0=plt.scatter(Inv_Norm_y(X_Sample[:, 2]), Inv_Norm_z(X_Sample[:, 3]), c=E_pred, s=2, cmap='plasma')\n",
    "    x_vals = x_min + (x_max - x_min) * np.random.rand(1000)\n",
    "    z_val  = z_max - L/2 + d/2\n",
    "    plt.scatter(x_vals, np.full_like(x_vals, z_val), c=\"red\", s=1)\n",
    "    z_val  = z_min+L/2 - d/2\n",
    "    plt.scatter(x_vals, np.full_like(x_vals, z_val), c=\"red\", s=1)\n",
    "    plt.title(f\"E(t={real_t:.2f} ns)\")\n",
    "    plt.xlabel(\"y coordinate [$\\\\mu$m]\")\n",
    "    if i_plot == 1:\n",
    "        plt.ylabel(\"z coordinate [$\\\\mu$m]\")\n",
    "    plt.xlim(y_min, y_max)\n",
    "    plt.ylim(z_min, z_max)\n",
    "    plt.colorbar(im0)\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.suptitle(\"Temporal evolution of V and E, plane x=-300\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"plot_c-2_plane_x-300.jpg\", format=\"jpg\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "# --- plane y=0 ---\n",
    "for i_plot, n_t in enumerate(sampled_times, 1):\n",
    "    real_t = Inv_Norm_time(n_t)\n",
    "    X_pred = torch.cat([\n",
    "        n_t * torch.ones_like(x_coords, device=device),\n",
    "        x_coords,\n",
    "        Norm_y( 0 * torch.ones_like(x_coords, device=device) ),\n",
    "        z_coords\n",
    "    ], dim=-1)\n",
    "    X_Sample = X_pred.detach().cpu().numpy()\n",
    "    X_pred.requires_grad=True\n",
    "    V_pred = model.forward(X_pred)\n",
    "    E_pred = ( (pde_class.get_derivative(V_pred, X_pred, 1)[:,1].unsqueeze(-1)/factor_x)**2 \\\n",
    "              + (pde_class.get_derivative(V_pred, X_pred, 1)[:,2].unsqueeze(-1)/factor_y)**2 \\\n",
    "              + (pde_class.get_derivative(V_pred, X_pred, 1)[:,3].unsqueeze(-1)/factor_z)**2 ) ** (1/2)\n",
    "    V_pred = V_pred.detach().cpu().numpy()\n",
    "    E_pred = E_pred.detach().cpu().numpy()\n",
    "    # ====== V ======\n",
    "    plt.subplot(n_plot, len(sampled_times), i_plot)\n",
    "    im0=plt.scatter(Inv_Norm_x(X_Sample[:, 1]), Inv_Norm_z(X_Sample[:, 3]), c=V_pred, s=2, cmap='plasma', vmin=v_min, vmax=v_max)\n",
    "    plt.title(f\"V(t={real_t:.2f} ns)\")\n",
    "    x_vals = x_min + (x_max - x_min) * np.random.rand(1000)\n",
    "    z_val  = z_max - L/2 + d/2\n",
    "    plt.scatter(x_vals, np.full_like(x_vals, z_val), c=\"red\", s=1)\n",
    "    z_val  = z_min+L/2 - d/2\n",
    "    plt.scatter(x_vals, np.full_like(x_vals, z_val), c=\"red\", s=1)\n",
    "    plt.xlabel(\"x coordinate [$\\\\mu$m]\")\n",
    "    if i_plot == 1:\n",
    "        plt.ylabel(\"z coordinate [$\\\\mu$m]\")\n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.ylim(z_min, z_max)\n",
    "    plt.colorbar(im0)\n",
    "    plt.tight_layout()\n",
    "    # ====== E ======\n",
    "    plt.subplot(n_plot, len(sampled_times), len(sampled_times) + i_plot)\n",
    "    im0=plt.scatter(Inv_Norm_x(X_Sample[:, 1]), Inv_Norm_z(X_Sample[:, 3]), c=E_pred, s=2, cmap='plasma')\n",
    "    plt.title(f\"E(t={real_t:.2f} ns)\")\n",
    "    x_vals = x_min + (x_max - x_min) * np.random.rand(1000)\n",
    "    z_val  = z_max - L/2 + d/2\n",
    "    plt.scatter(x_vals, np.full_like(x_vals, z_val), c=\"red\", s=1)\n",
    "    z_val  = z_min+L/2 - d/2\n",
    "    plt.scatter(x_vals, np.full_like(x_vals, z_val), c=\"red\", s=1)\n",
    "    plt.xlabel(\"x coordinate [$\\\\mu$m]\")\n",
    "    if i_plot == 1:\n",
    "        plt.ylabel(\"z coordinate [$\\\\mu$m]\")\n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.ylim(z_min, z_max)\n",
    "    plt.colorbar(im0)\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.suptitle(\"Temporal evolution of V and E, plane y=0\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"plot_c-2_plane_y0.jpg\", format=\"jpg\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "# --- plane z=0 ---\n",
    "for i_plot, n_t in enumerate(sampled_times, 1):\n",
    "    real_t = Inv_Norm_time(n_t)\n",
    "    X_pred = torch.cat([\n",
    "        n_t * torch.ones_like(x_coords, device=device),\n",
    "        x_coords,\n",
    "        y_coords,\n",
    "        Norm_z( 0 * torch.ones_like(x_coords, device=device) )\n",
    "    ], dim=-1)\n",
    "    X_Sample = X_pred.detach().cpu().numpy()\n",
    "    X_pred.requires_grad=True\n",
    "    V_pred = model.forward(X_pred)\n",
    "    E_pred = ( (pde_class.get_derivative(V_pred, X_pred, 1)[:,1].unsqueeze(-1)/factor_x)**2 \\\n",
    "              + (pde_class.get_derivative(V_pred, X_pred, 1)[:,2].unsqueeze(-1)/factor_y)**2 \\\n",
    "              + (pde_class.get_derivative(V_pred, X_pred, 1)[:,3].unsqueeze(-1)/factor_z)**2 ) ** (1/2)\n",
    "    V_pred = V_pred.detach().cpu().numpy()\n",
    "    E_pred = E_pred.detach().cpu().numpy()\n",
    "    # ====== V ======\n",
    "    plt.subplot(n_plot, len(sampled_times), i_plot)\n",
    "    im0=plt.scatter(Inv_Norm_x(X_Sample[:, 1]), Inv_Norm_y(X_Sample[:, 2]), c=V_pred, s=2, cmap='plasma', vmin=v_min, vmax=v_max)\n",
    "    plt.title(f\"V(t={real_t:.2f} ns)\")\n",
    "    plt.xlabel(\"x coordinate [$\\\\mu$m]\")\n",
    "    if i_plot == 1:\n",
    "        plt.ylabel(\"y coordinate [$\\\\mu$m]\")\n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.ylim(y_min, y_max)\n",
    "    plt.colorbar(im0)\n",
    "    plt.tight_layout()\n",
    "    # ====== E ======\n",
    "    plt.subplot(n_plot, len(sampled_times), len(sampled_times) + i_plot)\n",
    "    im0=plt.scatter(Inv_Norm_x(X_Sample[:, 1]), Inv_Norm_y(X_Sample[:, 2]), c=E_pred, s=2, cmap='plasma')\n",
    "    plt.title(f\"E(t={real_t:.2f} ns)\")\n",
    "    plt.xlabel(\"x coordinate [$\\\\mu$m]\")\n",
    "    if i_plot == 1:\n",
    "        plt.ylabel(\"y coordinate [$\\\\mu$m]\")\n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.ylim(y_min, y_max)\n",
    "    plt.colorbar(im0)\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.suptitle(\"Temporal evolution of V and E, plane z=0\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"plot_c-2_plane_z0.jpg\", format=\"jpg\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256bc38f-d6ed-4440-b87a-e80f755ab457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTION\n",
    "sampled_times = Norm_time( t_min + np.array([ 0, 0.1, 0.2, 0.3, 0.7, 1 ]) * (t_max - t_min) )\n",
    "n_samples = 20000\n",
    "plt.figure(figsize=(16,14))\n",
    "model.eval()\n",
    "sigma_model.eval()\n",
    "pde_class = QSM_PDE()\n",
    "\n",
    "for i_plot, n_t in enumerate(sampled_times, 1):\n",
    "    real_t = Inv_Norm_time(n_t)\n",
    "    X_pred = pde_class.gen_PDE_points(model, batch_size=n_samples)\n",
    "    X_pred[:,0] = n_t * torch.ones_like(X_pred[:,0], device=device)\n",
    "    X_Sample = X_pred.detach().cpu().numpy()\n",
    "    X_pred.requires_grad=True\n",
    "    V_pred = model.forward(X_pred)\n",
    "    \n",
    "    q_pred = V_pred\n",
    "    E_pred = ( (pde_class.get_derivative(V_pred, X_pred, 1)[:,1].unsqueeze(-1)/factor_x)**2 \\\n",
    "              + (pde_class.get_derivative(V_pred, X_pred, 1)[:,2].unsqueeze(-1)/factor_y)**2 \\\n",
    "              + (pde_class.get_derivative(V_pred, X_pred, 1)[:,3].unsqueeze(-1)/factor_z)**2 ) ** (1/2)\n",
    "    q_pred = q_pred.detach().cpu().numpy()\n",
    "    E_pred = E_pred.detach().cpu().numpy()\n",
    "\n",
    "    v_min = 0\n",
    "    v_max = V0\n",
    "    \n",
    "    # ====== VOLT ======\n",
    "    plt.subplot(4, len(sampled_times), i_plot)\n",
    "    im0=plt.scatter(Inv_Norm_x(X_Sample[:, 1]), Inv_Norm_z(X_Sample[:, 3]), c=q_pred, s=2, cmap='plasma', vmin=v_min, vmax=v_max)\n",
    "    x_vals = x_min + (x_max - x_min) * np.random.rand(1000)\n",
    "    z_val  = z_max - L/2 + d/2\n",
    "    plt.scatter(x_vals, np.full_like(x_vals, z_val), c=\"red\", s=1)\n",
    "    z_val  = z_min+L/2 - d/2\n",
    "    plt.scatter(x_vals, np.full_like(x_vals, z_val), c=\"red\", s=1)\n",
    "    plt.title(f\"V(t={real_t:.2f} ns)\")\n",
    "    plt.xlabel(\"x coordinate [$\\\\mu$m]\")\n",
    "    if i_plot == 1:\n",
    "        plt.ylabel(\"z coordinate [$\\\\mu$m]\")\n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.ylim(z_min, z_max)\n",
    "    plt.colorbar(im0)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # ====== VOLT UNIDIM ======\n",
    "    plt.subplot(4, len(sampled_times), len(sampled_times) + i_plot)\n",
    "    im2=plt.scatter(Inv_Norm_z(X_Sample[:, 3]), q_pred, s=1)\n",
    "    plt.title(f\"t = {real_t:.2f} ns\")\n",
    "    if i_plot == 1:\n",
    "        plt.ylabel(\"Potential [V]\")\n",
    "    plt.xlabel(\"z coordinate [$\\\\mu$m]\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # ====== ELECTRIC ======\n",
    "    v_min = 0\n",
    "    v_max = (V0 - 0) / ( norm_z_max - norm_z_min ) / factor_z\n",
    "    plt.subplot(4, len(sampled_times), 2*len(sampled_times) + i_plot)\n",
    "    im1=plt.scatter(Inv_Norm_x(X_Sample[:, 1]), Inv_Norm_z(X_Sample[:, 3]), c=E_pred, s=2, cmap='plasma', vmin=0, vmax=0.05)\n",
    "    x_vals = x_min + (x_max - x_min) * np.random.rand(1000)\n",
    "    z_val  = z_max - L/2 + d/2\n",
    "    plt.scatter(x_vals, np.full_like(x_vals, z_val), c=\"red\", s=1)\n",
    "    z_val  = z_min + L/2 - d/2\n",
    "    plt.scatter(x_vals, np.full_like(x_vals, z_val), c=\"red\", s=1)\n",
    "    plt.title(f\"E(t={real_t:.2f} ns)\")\n",
    "    plt.xlabel(\"x coordinate [$\\\\mu$m]\")\n",
    "    if i_plot == 1:\n",
    "        plt.ylabel(\"z coordinate [$\\\\mu$m]\")\n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.ylim(z_min, z_max)\n",
    "    plt.colorbar(im1)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # ====== ELECTRIC UNIDIM ======\n",
    "    plt.subplot(4, len(sampled_times), 3*len(sampled_times) + i_plot)\n",
    "    im3=plt.scatter(Inv_Norm_z(X_Sample[:, 3]), E_pred, s=1)\n",
    "    plt.ylim(0,0.06)\n",
    "    plt.title(f\"t = {real_t:.2f} ns\")\n",
    "    if i_plot == 1:\n",
    "        plt.ylabel(\"Electric field [V/$\\\\mu$m]\")\n",
    "    plt.xlabel(\"z coordinate [$\\\\mu$m]\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"plot_c-2_pred.jpg\", format=\"jpg\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063ca86d-14ab-406c-a2fe-7419fb991652",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = checkpoint[\"history\"]\n",
    "\n",
    "# PLOTS OF TRAINING AND VALIDATION STEPS\n",
    "# plot IC\n",
    "plt.plot([pair[0] for pair in history], label=\"Training\")\n",
    "plt.plot([pair[2] for pair in history], label=\"Validation\")\n",
    "plt.legend(title=\"IC error\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss values (MSE)\")\n",
    "plt.grid(alpha=0.2)\n",
    "plt.yscale(\"log\")\n",
    "plt.savefig(\"plot_c-2_IC.jpg\", format=\"jpg\", dpi=300)\n",
    "plt.show()\n",
    "# plot BC\n",
    "plt.plot([pair[8] for pair in history], label=\"Training\")\n",
    "plt.plot([pair[9] for pair in history], label=\"Validation\")\n",
    "plt.legend(title=\"BC error\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss values (MSE)\")\n",
    "plt.grid(alpha=0.2)\n",
    "plt.yscale(\"log\")\n",
    "plt.savefig(\"plot_c-2_BC.jpg\", format=\"jpg\", dpi=300)\n",
    "plt.show()\n",
    "# plot PDE CONDITIONS\n",
    "plt.plot([np.maximum(pair[1]/1e3, 1e-6) for pair in history], label=\"Training\")\n",
    "plt.plot([np.maximum(pair[3]/1e3, 1e-6) for pair in history], label=\"Validation\")\n",
    "plt.legend(title=\"PDE error\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss values (MSE)\")\n",
    "plt.grid(alpha=0.2)\n",
    "plt.yscale(\"log\")\n",
    "plt.savefig(\"plot_c-2_PDE.jpg\", format=\"jpg\", dpi=300)\n",
    "plt.show()\n",
    "# plot LAMBDA EFFECTIVE\n",
    "plt.plot([pair[6] for pair in history], label=\"lambda eff\")\n",
    "plt.legend(title=\"Lambda effective\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.grid(alpha=0.2)\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "# plot LEARNING RATE\n",
    "plt.plot([pair[7] for pair in history], label=\"lr\")\n",
    "plt.legend(title=\"Learning rate\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.grid(alpha=0.2)\n",
    "plt.yscale(\"log\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
    "# --- IC ---\n",
    "axs[0].plot([pair[0] for pair in history], label=\"Training\")\n",
    "axs[0].plot([pair[2] for pair in history], label=\"Validation\")\n",
    "axs[0].legend(title=\"IC error\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].set_ylabel(\"Loss values (MSE)\")\n",
    "axs[0].set_yscale(\"log\")\n",
    "axs[0].set_title(\"IC error\")\n",
    "axs[0].grid(alpha=0.2)\n",
    "# --- BC ---\n",
    "axs[1].plot([pair[8] for pair in history], label=\"Training\")\n",
    "axs[1].plot([pair[9] for pair in history], label=\"Validation\")\n",
    "axs[1].legend(title=\"BC error\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].set_ylabel(\"Loss values (MSE)\")\n",
    "axs[1].set_yscale(\"log\")\n",
    "axs[1].set_title(\"BC error\")\n",
    "axs[1].grid(alpha=0.2)\n",
    "# --- PDE CONDITIONS ---\n",
    "plt.plot([np.maximum(pair[1]/1e3, 1e-6) for pair in history], label=\"Training\")\n",
    "plt.plot([np.maximum(pair[3]/1e3, 1e-6) for pair in history], label=\"Validation\")\n",
    "axs[2].legend(title=\"PDE error\")\n",
    "axs[2].set_xlabel(\"Epoch\")\n",
    "axs[2].set_ylabel(\"Loss values (MSE)\")\n",
    "axs[2].set_yscale(\"log\")\n",
    "axs[2].set_title(\"PDE error\")\n",
    "axs[2].grid(alpha=0.2)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"plot_c-2_history.jpg\", format=\"jpg\", dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Piint Pytorch",
   "language": "python",
   "name": "piint-torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
